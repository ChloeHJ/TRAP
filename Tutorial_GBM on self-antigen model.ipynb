{"cells":[{"cell_type":"markdown","source":["\n","\n","*  This tutorial aims to predict immunogenicity of peptides derived from glioblastoma patients using self-antigen model\n","*  All data and models can be retrieved from https://drive.google.com/drive/folders/15A2P5xP2c-q48vVGPRB7h7uHEMycPYoX?usp=drive_link \n","\n","\n"],"metadata":{"id":"Ww3txmBAL1cB"}},{"cell_type":"code","source":["!pip install -q transformers\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObfX-57snlkY","executionInfo":{"status":"ok","timestamp":1674315908637,"user_tz":0,"elapsed":15812,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"d48eb955-2173-4a2e-c887-19edf184a074"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9478,"status":"ok","timestamp":1674315874824,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"},"user_tz":0},"id":"gAbYf-4wqDgZ","outputId":"f0337cb1-05af-444f-fb14-a541f7a1fdab"},"outputs":[{"output_type":"stream","name":"stdout","text":["transformers version: 4.25.1\n","tensorflow version: 2.9.2\n","keras version: 2.9.0\n","3.8.10 (default, Nov 14 2022, 12:59:47) \n","[GCC 9.4.0]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import sys\n","import csv\n","import random\n","import os as os\n","from io import StringIO\n","import keras\n","from tensorflow.keras import layers\n","from keras.layers import Input,Dense,concatenate,Dropout,AveragePooling2D\n","from keras.models import Model,load_model                                                      \n","from keras import backend as K\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import auc,precision_recall_curve,roc_curve,confusion_matrix\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, Input, LSTM, RNN, SimpleRNN, Bidirectional, Concatenate, GlobalMaxPool1D, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Conv2D\n","from keras.utils.vis_utils import plot_model\n","import transformers\n","from transformers import T5Tokenizer, T5Model, BertModel, BertForMaskedLM, BertTokenizer, pipeline, BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n","from transformers import TFBertModel, TFXLNetModel, XLNetTokenizer,XLNetConfig, TFT5EncoderModel\n","import re\n","import pickle\n","import seaborn as sb\n","import matplotlib.pyplot as plt\n","from keras_preprocessing.sequence import pad_sequences\n","\n","print('transformers version: %s' %transformers.__version__)\n","print('tensorflow version: %s' %tf.__version__)\n","print('keras version: %s' %keras.__version__)\n","print(sys.version)"]},{"cell_type":"markdown","metadata":{"id":"YPuYDdSmczWU"},"source":["### Auxiliary functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MY8LZwQOc3St"},"outputs":[],"source":["# plotting scripts \n","from tensorflow.keras.optimizers import Adam\n","\n","# ROC\n","def draw_roc(bucket_roc):\n","    bucket = bucket_roc\n","    fig,ax = plt.subplots()\n","    for i in range(10):\n","        ax.plot(bucket[i][0],bucket[i][1],lw=0.5,label='CV(Fold={0}), AUC={1:.2f}'.format(i+1,bucket[i][3]))\n","    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    ax.set_xlim([0.0, 1.0])\n","    ax.set_ylim([0.0, 1.05])\n","    ax.set_xlabel('False Positive Rate')\n","    ax.set_ylabel('True Positive Rate')\n","    ax.set_title('Receiver operating characteristic')\n","    ax.legend(loc=\"lower right\",fontsize=9)\n","    plt.show()\n","\n","# PR\n","def draw_pr(bucket_pr):\n","    bucket = bucket_pr\n","    fig,ax = plt.subplots()\n","    for i in range(10):\n","        ax.plot(bucket[i][1],bucket[i][0],lw=0.5,label='CV(Fold={0}),AUC={1:.2f}'.format(i+1,bucket[i][3]))\n","    #baseline = np.sum(np.array(y_true) == 1) / len(y_true)  # 0.4735\n","    baseline = 0.4735\n","    ax.plot([0, 1], [baseline, baseline], color='navy', lw=2, linestyle='--')\n","    ax.set_xlim([0.0, 1.0])\n","    #ax.set_ylim([0.0, 1.05])\n","    ax.set_xlabel('Recall')\n","    ax.set_ylabel('Precision')\n","    ax.set_title('PR curve example')\n","    ax.legend(loc=\"lower left\",fontsize=8)\n","    plt.show()\n","\n","\n","def draw_history(history):\n","    # history for accuracy \n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","\n","    # summarize history for loss\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","\n","\n","METRICS = [\n","    keras.metrics.TruePositives(name='tp'),\n","    keras.metrics.FalsePositives(name='fp'),\n","    keras.metrics.TrueNegatives(name='tn'),\n","    keras.metrics.FalseNegatives(name='fn'),\n","    keras.metrics.BinaryAccuracy(name='accuracy'),\n","    keras.metrics.Precision(name='precision'),\n","    keras.metrics.Recall(name='recall'),\n","    keras.metrics.AUC(name='auc'),\n","]\n","\n","\n","def evaluate_roc_pr_10cv(test_model, X_train, y_train):\n","    # let's do a train/validation split\n","    bucket_roc = []\n","    bucket_pr = []\n","    for i in range(10):\n","        array = np.arange(len(X_train))\n","        train_index = np.random.choice(array,int(len(X_train)*0.9),replace=False)\n","        valid_index = [item for item in array if item not in train_index]\n","\n","        input1_train = X_train[train_index]\n","        input1_valid = X_train[valid_index]\n","        label_train = y_train[train_index]\n","        label_valid = y_train[valid_index]\n","\n","        model = test_model(X_train)\n","        callback_val = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=False)\n","        callback_train = keras.callbacks.EarlyStopping(monitor='loss',patience=2,restore_best_weights=False)\n","        history = model.fit(\n","            x=[input1_train],   # feed a list into\n","            y=label_train,\n","            validation_data = ([input1_valid],label_valid),\n","            batch_size=128,\n","            epochs=200,\n","            callbacks = [callback_val,callback_train])\n","\n","        y_true = label_valid\n","        y_pred = model.predict([input1_valid])\n","\n","        fpr,tpr,_ = roc_curve(y_true,y_pred)\n","        area = auc(fpr,tpr)\n","        bucket_roc.append((fpr,tpr,_,area))\n","\n","        precision, recall, _ = precision_recall_curve(y_true, y_pred)\n","        area = auc(recall, precision)\n","        bucket_pr.append((precision, recall, _, area))\n","\n","    draw_roc(bucket_roc)\n","    draw_pr(bucket_pr)\n","\n","    \n","def evaluate_roc_pr_mlp_10cv(test_model, X_train, X_train_mlp, y_train):\n","    # let's do a train/validation split\n","    bucket_roc = []\n","    bucket_pr = []\n","    for i in range(10):\n","        array = np.arange(len(X_train))\n","        train_index = np.random.choice(array,int(len(X_train)*0.9),replace=False)\n","        valid_index = [item for item in array if item not in train_index]\n","\n","        input1_train = X_train[train_index]\n","        input1_valid = X_train[valid_index]\n","        input1_mlp_train = X_train_mlp.iloc[train_index]\n","        input1_mlp_valid = X_train_mlp.iloc[valid_index]\n","        label_train = y_train[train_index]\n","        label_valid = y_train[valid_index]\n","\n","        model = test_model(X_train)\n","        callback_val = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=False)\n","        callback_train = keras.callbacks.EarlyStopping(monitor='loss',patience=2,restore_best_weights=False)\n","        history = model.fit(\n","            x=[input1_train, input1_mlp_train],   # feed a list into\n","            y=label_train,\n","            validation_data = ([input1_valid, input1_mlp_valid],label_valid),\n","            batch_size=128,\n","            epochs=200,\n","            callbacks = [callback_val,callback_train])\n","\n","        y_true = label_valid\n","        y_pred = model.predict([input1_valid, input1_mlp_valid])\n","\n","        fpr,tpr,_ = roc_curve(y_true,y_pred)\n","        area = auc(fpr,tpr)\n","        bucket_roc.append((fpr,tpr,_,area))\n","\n","        precision, recall, _ = precision_recall_curve(y_true, y_pred)\n","        area = auc(recall, precision)\n","        bucket_pr.append((precision, recall, _, area))\n","\n","    draw_roc(bucket_roc)\n","    draw_pr(bucket_pr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glNRDF8wc3Us"},"outputs":[],"source":["# ROC\n","def draw_1roc(bucket_roc):\n","    bucket = bucket_roc\n","    fig,ax = plt.subplots()\n","    for i in range(1):\n","        ax.plot(bucket[i][0],bucket[i][1],lw=0.5,label='CV(Fold={0}), AUC={1:.2f}'.format(i+1,bucket[i][3]))\n","    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    ax.set_xlim([0.0, 1.0])\n","    ax.set_ylim([0.0, 1.05])\n","    ax.set_xlabel('False Positive Rate')\n","    ax.set_ylabel('True Positive Rate')\n","    ax.set_title('Receiver operating characteristic')\n","    ax.legend(loc=\"lower right\",fontsize=9)\n","    plt.show()\n","\n","# PR\n","def draw_1pr(bucket_pr):\n","    bucket = bucket_pr\n","    fig,ax = plt.subplots()\n","    for i in range(1):\n","        ax.plot(bucket[i][1],bucket[i][0],lw=0.5,label='CV(Fold={0}),AUC={1:.2f}'.format(i+1,bucket[i][3]))\n","    #baseline = np.sum(np.array(y_true) == 1) / len(y_true)  # 0.4735\n","    baseline = 0.4735\n","    ax.plot([0, 1], [baseline, baseline], color='navy', lw=2, linestyle='--')\n","    ax.set_xlim([0.0, 1.0])\n","    #ax.set_ylim([0.0, 1.05])\n","    ax.set_xlabel('Recall')\n","    ax.set_ylabel('Precision')\n","    ax.set_title('PR curve example')\n","    ax.legend(loc=\"lower left\",fontsize=8)\n","    plt.show()\n","\n","\n","def evaluate_roc_pr_mlp_1cv(test_model, X_train, X_train_mlp, y_train):\n","    # let's do a train/validation split\n","    bucket_roc = []\n","    bucket_pr = []\n","    for i in range(1):\n","        array = np.arange(len(X_train))\n","        train_index = np.random.choice(array,int(len(X_train)*0.9),replace=False)\n","        valid_index = [item for item in array if item not in train_index]\n","\n","        input1_train = X_train[train_index]\n","        input1_valid = X_train[valid_index]\n","        input1_mlp_train = X_train_mlp.iloc[train_index]\n","        input1_mlp_valid = X_train_mlp.iloc[valid_index]\n","        label_train = y_train[train_index]\n","        label_valid = y_train[valid_index]\n","\n","        model = test_model(X_train)\n","        callback_val = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=False)\n","        callback_train = keras.callbacks.EarlyStopping(monitor='loss',patience=2,restore_best_weights=False)\n","        history = model.fit(\n","            x=[input1_train, input1_mlp_train],   # feed a list into\n","            y=label_train,\n","            validation_data = ([input1_valid, input1_mlp_valid],label_valid),\n","            batch_size=128,\n","            epochs=200,\n","            callbacks = [callback_val,callback_train])\n","\n","        y_true = label_valid\n","        y_pred = model.predict([input1_valid, input1_mlp_valid])\n","\n","        fpr,tpr,_ = roc_curve(y_true,y_pred)\n","        area = auc(fpr,tpr)\n","        bucket_roc.append((fpr,tpr,_,area))\n","\n","        precision, recall, _ = precision_recall_curve(y_true, y_pred)\n","        area = auc(recall, precision)\n","        bucket_pr.append((precision, recall, _, area))\n","\n","    draw_1roc(bucket_roc)\n","    draw_1pr(bucket_pr)\n","\n","\n","def evaluate_roc_pr_1cv(test_model, X_train, y_train):\n","    # let's do a train/validation split\n","    bucket_roc = []\n","    bucket_pr = []\n","    for i in range(1):\n","        array = np.arange(len(X_train))\n","        train_index = np.random.choice(array,int(len(X_train)*0.9),replace=False)\n","        valid_index = [item for item in array if item not in train_index]\n","\n","        input1_train = X_train[train_index]\n","        input1_valid = X_train[valid_index]\n","        label_train = y_train[train_index]\n","        label_valid = y_train[valid_index]\n","\n","        model = test_model(X_train)\n","        callback_val = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=False)\n","        callback_train = keras.callbacks.EarlyStopping(monitor='loss',patience=2,restore_best_weights=False)\n","        history = model.fit(\n","            x=[input1_train],   # feed a list into\n","            y=label_train,\n","            validation_data = ([input1_valid],label_valid),\n","            batch_size=128,\n","            epochs=200,\n","            callbacks = [callback_val,callback_train])\n","\n","        y_true = label_valid\n","        y_pred = model.predict([input1_valid])\n","\n","        fpr,tpr,_ = roc_curve(y_true,y_pred)\n","        area = auc(fpr,tpr)\n","        bucket_roc.append((fpr,tpr,_,area))\n","\n","        precision, recall, _ = precision_recall_curve(y_true, y_pred)\n","        area = auc(recall, precision)\n","        bucket_pr.append((precision, recall, _, area))\n","\n","    draw_1roc(bucket_roc)\n","    draw_1pr(bucket_pr)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ipbW3VnsuSOX"},"source":["## Data preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_t3Vc8IhuT1S"},"outputs":[],"source":["def add_space_to_pep(peptides):\n","    peptide_space = [] \n","    for ele in peptides:\n","        temp = [[]]\n","        for char in ele:\n","            temp.append([])\n","            temp[-1].append(char) \n","        peptide_space.append(' '.join(''.join(ele) for ele in temp))\n","    peptide_space = [re.sub(r\"[UZOB]\", \"X\", sequence.lstrip()) for sequence in peptide_space]\n","\n","    return peptide_space"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O5F10-gLB7wh"},"outputs":[],"source":["# training dataset \n","sdata = pd.read_csv('data/selfantigen_data_forMODEL.csv')\n","\n","sdata['Immunogenicity'] = sdata['Immunogenicity'].replace(['Positive', 'Positive-Low', 'Positive-Intermediate', 'Positive-High', 'Negative'], [1, 1,1,1,0])\n","y_train  = sdata['Immunogenicity'].values"]},{"cell_type":"code","source":["# test dataset\n","gbm_test = pd.read_csv('data/GBM_data_forTRAP.csv')\n","gbm_test.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"HM9ytdgtBSQa","executionInfo":{"status":"ok","timestamp":1674219007641,"user_tz":0,"elapsed":459,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"ad8e241d-e710-439d-9c8e-29dc8d23b7d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Peptide  n_hydrophobic Immunogenicity  length  Hydrophobicity  \\\n","0  FLEEIILKSL              3       Negative      10        0.300000   \n","1   FLRESQNPL              2       Negative       9        0.222222   \n","2  GLALGTPLSI              4       Negative      10        0.400000   \n","3   GLAVNLSQI              4       Negative       9        0.444444   \n","4  GNLPDIEVRL              3       Negative      10        0.300000   \n","\n","  MHC_Restriction    Rank  nlog2Rank ContactPosition  \n","0     HLA-A*02:01  0.3277   1.609552         EEIILKS  \n","1     HLA-A*02:01  0.5335   0.906440          RESQNP  \n","2     HLA-A*02:01  0.5356   0.900772         ALGTPLS  \n","3     HLA-A*02:01  0.5529   0.854910          AVNLSQ  \n","4     HLA-A*02:01  0.5854   0.772505         LPDIEVR  "],"text/html":["\n","  <div id=\"df-922f5db6-625e-469e-a0f7-28c46bb60b17\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Peptide</th>\n","      <th>n_hydrophobic</th>\n","      <th>Immunogenicity</th>\n","      <th>length</th>\n","      <th>Hydrophobicity</th>\n","      <th>MHC_Restriction</th>\n","      <th>Rank</th>\n","      <th>nlog2Rank</th>\n","      <th>ContactPosition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FLEEIILKSL</td>\n","      <td>3</td>\n","      <td>Negative</td>\n","      <td>10</td>\n","      <td>0.300000</td>\n","      <td>HLA-A*02:01</td>\n","      <td>0.3277</td>\n","      <td>1.609552</td>\n","      <td>EEIILKS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FLRESQNPL</td>\n","      <td>2</td>\n","      <td>Negative</td>\n","      <td>9</td>\n","      <td>0.222222</td>\n","      <td>HLA-A*02:01</td>\n","      <td>0.5335</td>\n","      <td>0.906440</td>\n","      <td>RESQNP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GLALGTPLSI</td>\n","      <td>4</td>\n","      <td>Negative</td>\n","      <td>10</td>\n","      <td>0.400000</td>\n","      <td>HLA-A*02:01</td>\n","      <td>0.5356</td>\n","      <td>0.900772</td>\n","      <td>ALGTPLS</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GLAVNLSQI</td>\n","      <td>4</td>\n","      <td>Negative</td>\n","      <td>9</td>\n","      <td>0.444444</td>\n","      <td>HLA-A*02:01</td>\n","      <td>0.5529</td>\n","      <td>0.854910</td>\n","      <td>AVNLSQ</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GNLPDIEVRL</td>\n","      <td>3</td>\n","      <td>Negative</td>\n","      <td>10</td>\n","      <td>0.300000</td>\n","      <td>HLA-A*02:01</td>\n","      <td>0.5854</td>\n","      <td>0.772505</td>\n","      <td>LPDIEVR</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-922f5db6-625e-469e-a0f7-28c46bb60b17')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-922f5db6-625e-469e-a0f7-28c46bb60b17 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-922f5db6-625e-469e-a0f7-28c46bb60b17');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["gbm_peptides = gbm_test.ContactPosition.values\n","gbm_input_peptides = add_space_to_pep(gbm_peptides)\n","gbm_test['Immunogenicity'] = gbm_test['Immunogenicity'].replace(['Positive', 'Positive-Low', 'Positive-Intermediate', 'Positive-High', 'Negative'], [1, 1,1,1,0])\n","y_test_gbm  = gbm_test['Immunogenicity'].values"],"metadata":{"id":"WnkbxoGWBSSp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XPuHX3bKueKF"},"source":["## Embed sequence\n","\n","\n","*   Here, all peptides are post-padded seeing there isn't much difference between P3 padding and post-padding from previous analysis\n","*   Can do P3 padding - by instead of using tokenizer, do mid-padding as done in the previous script\n"]},{"cell_type":"code","source":["tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False )\n","model = TFT5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", from_pt=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aefUC3MEBuei","executionInfo":{"status":"ok","timestamp":1664653914556,"user_tz":-60,"elapsed":79494,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"1598378d-d930-41fb-bd79-43b82936cf29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5EncoderModel: ['decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.final_layer_norm.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'encoder.embed_tokens.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.embed_tokens.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'lm_head.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight']\n","- This IS expected if you are initializing TFT5EncoderModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFT5EncoderModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFT5EncoderModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5EncoderModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["tokenized_texts = [tokenizer.tokenize(sent) for sent in gbm_input_peptides]\n","input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts], padding=\"pre\")\n","\n","attention_masks = []\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","# Extracting sequences' features and load it into the CPU if needed\n","embedding = model(input_ids=input_ids)[0]\n","embedding = np.asarray(embedding)\n","pickle.dump( embedding, open( \"output/gbm/protT5_xl_gbm_test.pkl\", \"wb\" ) )"],"metadata":{"id":"ahyHiG9ZBugq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"si_6Vr1tBuij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9aZE23lZ__qc"},"source":["## Load peptide enbedded matrix\n","\n","Same strategy was used to embed peptides from selfantigen_data_forMODEL dataset to prepare protT5_xl_peptides_1_train data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCF7neQr_-7U"},"outputs":[],"source":["# train dataset\n","protT5_xl_peptides_1_train = pickle.load( open( \"output/bert_embedded_contacts_selfantigen/protT5_xl_peptides.pkl\", \"rb\" ) )\n","\n","# test dataset \n","protT5_xl_peptides_1_gbm_test = pickle.load( open( \"output/gbm/protT5_xl_gbm_test.pkl\", \"rb\" ) )\n"]},{"cell_type":"markdown","source":["## TRAP-1 model\n","\n","The self-antigen TRAP-1 model was trained using peptides in selfantigen_data_forMODEL dataset"],"metadata":{"id":"CR7MdWgKmTlZ"}},{"cell_type":"code","source":["# load pretrained softmax model \n","self_trap = tf.keras.models.load_model('model/self_antigen_trap_softmax_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SNLgwHWhNvLy","executionInfo":{"status":"ok","timestamp":1674219202171,"user_tz":0,"elapsed":4704,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"0246cbc2-3de9-44df-d63f-e16d27d8470b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["# make prediction on test peptides\n","# this compute predictions 100 times with monte carlo dropouts \n","bucket_test_DO = []\n","for i in range(100):\n","    peptides = gbm_test[['Peptide', 'nlog2Rank']]\n","    model_score = Model(self_trap.input, self_trap.get_layer('logits').output)\n","    X_test_DO = model_score.predict(x = [protT5_xl_peptides_1_gbm_test, gbm_test[['Hydrophobicity', 'nlog2Rank']]])\n","    X_test_DO = np.concatenate((X_test_DO, peptides),axis=1)\n","    bucket_test_DO.append(X_test_DO)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FM4GxDTiCBKq","executionInfo":{"status":"ok","timestamp":1674221690417,"user_tz":0,"elapsed":26474,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"b6f26b3a-d357-4497-f8a3-6461be258b54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 11ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 1s 10ms/step\n","4/4 [==============================] - 1s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 10ms/step\n","4/4 [==============================] - 0s 11ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 10ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 9ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n","4/4 [==============================] - 0s 8ms/step\n"]}]},{"cell_type":"code","source":["# process output to compute average monte carlo dropout softmax probabilities \n","test_DO_DT = pd.DataFrame(np.vstack((bucket_test_DO)))\n","test_DO_DT.columns = [\"X0\", \"X1\", \"Peptide\", 'nlog2Rank']\n","test_DO_DT = test_DO_DT.groupby(['Peptide', 'nlog2Rank']).agg(  #from here, become alphabetical \n","    avg_X0 = pd.NamedAgg(column ='X0', aggfunc='mean'),\n","    avg_X1 = pd.NamedAgg(column ='X1', aggfunc='mean'))\n","test_DO_DT['maxprob_mean_dropout'] = test_DO_DT[['avg_X0', 'avg_X1']].max(axis=1)\n","test_DO_DT['TRAP'] = np.where((test_DO_DT['avg_X1'] >= test_DO_DT['avg_X0']), 'Positive', 'Negative')\n","test_DO_DT = test_DO_DT.reset_index()  \n","test_DO_DT.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"N1O4ZCQMRVQe","executionInfo":{"status":"ok","timestamp":1674221958203,"user_tz":0,"elapsed":239,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"d9025d6d-11ee-491a-b4d0-4d737c4c214a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Peptide  nlog2Rank    avg_X0    avg_X1  maxprob_mean_dropout      TRAP\n","0   AAIESFVSV   1.493297  7.646901 -8.020171              7.646901  Negative\n","1   ALAGGLYEY  -0.722728  7.523490 -7.791161              7.523490  Negative\n","2   ALFCHQYDI   0.199090 -2.897632  2.792828              2.792828  Positive\n","3  ALGALLILQL  -0.725349  3.503604 -3.719930              3.503604  Negative\n","4   ALKSDFKLV  -0.480886  6.158325 -6.260597              6.158325  Negative"],"text/html":["\n","  <div id=\"df-74f01756-3249-4dd1-b525-756a9a65f3ef\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Peptide</th>\n","      <th>nlog2Rank</th>\n","      <th>avg_X0</th>\n","      <th>avg_X1</th>\n","      <th>maxprob_mean_dropout</th>\n","      <th>TRAP</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAIESFVSV</td>\n","      <td>1.493297</td>\n","      <td>7.646901</td>\n","      <td>-8.020171</td>\n","      <td>7.646901</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ALAGGLYEY</td>\n","      <td>-0.722728</td>\n","      <td>7.523490</td>\n","      <td>-7.791161</td>\n","      <td>7.523490</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ALFCHQYDI</td>\n","      <td>0.199090</td>\n","      <td>-2.897632</td>\n","      <td>2.792828</td>\n","      <td>2.792828</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ALGALLILQL</td>\n","      <td>-0.725349</td>\n","      <td>3.503604</td>\n","      <td>-3.719930</td>\n","      <td>3.503604</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ALKSDFKLV</td>\n","      <td>-0.480886</td>\n","      <td>6.158325</td>\n","      <td>-6.260597</td>\n","      <td>6.158325</td>\n","      <td>Negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74f01756-3249-4dd1-b525-756a9a65f3ef')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-74f01756-3249-4dd1-b525-756a9a65f3ef button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-74f01756-3249-4dd1-b525-756a9a65f3ef');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","source":["## OOD classifier"],"metadata":{"id":"2lPhZkG4U8Gc"}},{"cell_type":"code","source":["from sklearn import linear_model\n","ood_data = pd.read_csv('data/ood_dropout_selfantigen.csv') # data for training OOD classifier \n","X = ood_data[['maxprob_mean_dropout']]\n","y = ood_data.iloc[:,-1]\n","model = linear_model.LinearRegression().fit(X, y)"],"metadata":{"id":"J5WIejZNU9uZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make prediciton on OOD classifier \n","y_pred = model.predict(test_DO_DT[['maxprob_mean_dropout']])\n","ood_dt = pd.DataFrame(y_pred); ood_dt.columns = ['Confidence']"],"metadata":{"id":"eRZf56EgWpmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trap_output = pd.concat([test_DO_DT.reset_index(drop=True), ood_dt.reset_index(drop=True)], axis=1)\n","trap_output = trap_output[[\"Peptide\", 'nlog2Rank', \"TRAP\", 'maxprob_mean_dropout', 'Confidence']]\n","trap_output.head()\n","trap_output.to_csv('output/protT5_xl_gbm_test_prediction.csv')"],"metadata":{"id":"IDKyPR07WMxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_QYIVNdW6NBv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# App demonstration on GBM data"],"metadata":{"id":"yq6Mmn_5NVz3"}},{"cell_type":"code","source":["def parse_data(contents, filename):\n","    content_type, content_string = contents.split(',')\n","\n","    decoded = base64.b64decode(content_string)\n","    try:\n","        if 'csv' in filename:\n","            # Assume that the user uploaded a CSV or TXT file\n","            df = pd.read_csv(\n","                io.StringIO(decoded.decode('utf-8')))\n","        elif 'xls' in filename:\n","            # Assume that the user uploaded an excel file\n","            df = pd.read_excel(io.BytesIO(decoded))\n","        elif 'txt' or 'tsv' in filename:\n","            # Assume that the user upl, delimiter = r'\\s+'oaded an excel file\n","            df = pd.read_csv(\n","                io.StringIO(decoded.decode('utf-8')), delimiter = r'\\s+')\n","    except Exception as e:\n","        print(e)\n","        return html.Div([\n","            'There was an error processing this file.'\n","        ])\n","\n","    return df\n","\n","\n","def add_space_to_pep(peptides):\n","    peptide_space = [] \n","    for ele in peptides:\n","        temp = [[]]\n","        for char in ele:\n","            temp.append([])\n","            temp[-1].append(char) \n","        peptide_space.append(' '.join(''.join(ele) for ele in temp))\n","    peptide_space = [re.sub(r\"[UZOB]\", \"X\", sequence.lstrip()) for sequence in peptide_space]\n","\n","    return peptide_space\n","\n","def preprocess_test_peptides(test_data):\n","\n","    # add contact positions \n","    cont_peptides = []\n","    hydrophobicity = []\n","    for pep in test_data.Peptide:\n","      cont_pep = pep[2:-1]\n","      cont_peptides.append(cont_pep)\n","      hyd_counts = pep.count('A') + pep.count('V') + pep.count('L') + pep.count('M') + pep.count('W')\n","      length = len(pep)\n","      hydrophobicity.append(hyd_counts/length)\n","\n","    cont_peptides = pd.DataFrame(cont_peptides); cont_peptides.columns = ['ContactPosition']\n","    hydrophobicity = pd.DataFrame(hydrophobicity); hydrophobicity.columns = ['Hydrophobicity']\n","    test_data = pd.concat([test_data, cont_peptides, hydrophobicity], axis=1)\n","\n","    return test_data\n","\n","def embed_test_peptides(test_data, tokenizer, TFT5EncoderModel):\n","    # embed test peptides \n","    test_peptides = test_data.ContactPosition.values\n","    input_peptides = add_space_to_pep(test_peptides)\n","      \n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in input_peptides]\n","    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts], padding=\"pre\")\n","\n","    attention_masks = []\n","    for seq in input_ids:\n","      seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","    embedding = TFT5EncoderModel(input_ids=input_ids)[0]\n","    embedding = np.asarray(embedding)\n","\n","    return embedding\n","\n","############## THIS WORKING IN PROGRESS ##########################\n","def predict_trap(emebedding, test_data, trap, trap_ood):\n","    \n","  X_test = emebedding\n","  X_test_mlp = test_data[['Hydrophobicity', 'nlog2Rank']]\n","\n","  # trap \n","  y_pred = trap.predict([X_test, X_test_mlp])\n","  trap_pred = pd.DataFrame(y_pred); trap_pred.columns = ['TRAP']\n","\n","  # trap-ood\n","  bucket_test_DO = []\n","  for i in range(100):\n","      peptides = test_data[['Peptide', 'nlog2Rank']]\n","      model_score = Model(trap.input, trap.get_layer('logits').output)\n","      X_test_DO = model_score.predict(x = [X_test, test_data[['Hydrophobicity', 'nlog2Rank']]])\n","      X_test_DO = np.concatenate((X_test_DO, peptides),axis=1)\n","      bucket_test_DO.append(X_test_DO)\n","\n","  test_DO_DT = pd.DataFrame(np.vstack((bucket_test_DO)))\n","  test_DO_DT.columns = [\"X0\", \"X1\", \"Peptide\", 'nlog2Rank']\n","  test_DO_DT = test_DO_DT.groupby(['Peptide', 'nlog2Rank']).agg(  #from here, become alphabetical \n","      avg_X0 = pd.NamedAgg(column ='X0', aggfunc='mean'),\n","      avg_X1 = pd.NamedAgg(column ='X1', aggfunc='mean'))\n","  test_DO_DT['maxprob_mean_dropout'] = test_DO_DT[['avg_X0', 'avg_X1']].max(axis=1)\n","  #test_DO_DT['TRAP'] = np.where((test_DO_DT['avg_X1'] >= test_DO_DT['avg_X0']), 'Positive', 'Negative')\n","  test_DO_DT = test_DO_DT.reset_index()  \n","\n","  # ood classifier\n","  y_pred = trap_ood.predict(test_DO_DT[['maxprob_mean_dropout']])\n","  ood_dt = pd.DataFrame(y_pred); ood_dt.columns = ['Confidence']\n","\n","  # process outputs\n","  trap_output = pd.concat([test_DO_DT.reset_index(drop=True), ood_dt.reset_index(drop=True)], axis=1)\n","    # need to left_join  \n","  trap_output = trap_output[[\"Peptide\", 'nlog2Rank', \"TRAP\", 'maxprob_mean_dropout', 'Confidence']] \n","  trap_output.rename(columns={\"MCDropout\": \"maxprob_mean_dropout\"})\n","\n","  return trap_output\n"],"metadata":{"id":"92ZLIedGNapN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data loading "],"metadata":{"id":"_taVVTnYN8iT"}},{"cell_type":"code","source":["from sklearn import linear_model\n","\n","######### tokenizer and embedding ###########\n","# tokenizer = T5Tokenizer.from_pretrained(\"rostlab/prot_t5_xl_uniref50\", do_lower_case=False )\n","# TFT5EncoderModel = TFT5EncoderModel.from_pretrained(\"rostlab/prot_t5_xl_uniref50\", from_pt=True)\n","\n","########### OOD model #####################\n","# selfantigen model\n","self_trap = tf.keras.models.load_model('model/self_antigen_trap_model')\n","self_trap_softmax = tf.keras.models.load_model('model/selfantigen_trap_softmax_model')\n","ood_selfantigen_data = pd.read_csv('data/ood_dropout_selfantigen.csv')\n","self_trap_ood = linear_model.LinearRegression().fit(ood_selfantigen_data[['maxprob_mean_dropout']], ood_selfantigen_data.iloc[:,-1])\n","\n","# pathogenic model \n","path_trap = tf.keras.models.load_model('model/pathogenic_trap_model')\n","path_trap_softmax = tf.keras.models.load_model('model/pathogenic_trap_softmax_model')\n","ood_pathogenic_data = pd.read_csv('data/ood_dropout_pathogenic.csv')\n","path_trap_ood = linear_model.LinearRegression().fit(ood_pathogenic_data[['maxprob_mean_dropout']], ood_pathogenic_data.iloc[:,-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_uTJPzkO0sk","executionInfo":{"status":"ok","timestamp":1674315943374,"user_tz":0,"elapsed":30747,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"3e00dd6e-5d50-4c80-916f-3b50018b44fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}]},{"cell_type":"code","source":["# test dataset \n","emebedding = pickle.load( open( \"output/gbm/protT5_xl_gbm_test.pkl\", \"rb\" ) )\n","gbm_data = pd.read_csv('data/GBM_data_forTRAP.csv')"],"metadata":{"id":"PW4cxM7bPYTT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data processing "],"metadata":{"id":"FgbN1EUqO3Af"}},{"cell_type":"code","source":["###### INPUTS TO FUNCTION ###############\n","test_data = gbm_data\n","trap = self_trap\n","trap_softmax = self_trap_softmax\n","trap_ood = self_trap_ood"],"metadata":{"id":"RmrGO6dMQL9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### FUNCTION ############### \n","test_data = test_data[['Peptide', 'Hydrophobicity', 'nlog2Rank']].sort_values(['Peptide', 'nlog2Rank']).drop_duplicates().reset_index()\n","X_test_mlp = test_data[['Hydrophobicity', 'nlog2Rank']]\n","\n","# do embedding here \n","\n","# trap \n","y_pred = trap.predict([X_test, X_test_mlp])\n","trap_pred = pd.DataFrame(y_pred); trap_pred.columns = ['TRAP']\n","trap_pred = pd.concat([test_data[['Peptide', 'nlog2Rank']].reset_index(drop = True), trap_pred.reset_index(drop = True)], axis=1)  \n","    # output: peptide, nlog2, trap \n","\n","# trap-ood\n","bucket_test_DO = []\n","for i in range(100):\n","    peptides = test_data[['Peptide', 'nlog2Rank']]\n","    model_score = Model(trap_softmax.input, trap_softmax.get_layer('logits').output)\n","    X_test_DO = model_score.predict(x = [X_test, test_data[['Hydrophobicity', 'nlog2Rank']]])\n","    X_test_DO = np.concatenate((X_test_DO, peptides),axis=1)\n","    bucket_test_DO.append(X_test_DO)\n","\n","test_DO_DT = pd.DataFrame(np.vstack((bucket_test_DO)))\n","test_DO_DT.columns = [\"X0\", \"X1\", \"Peptide\", 'nlog2Rank']\n","test_DO_DT = test_DO_DT.groupby(['Peptide', 'nlog2Rank']).agg(  #from here, become alphabetical \n","    avg_X0 = pd.NamedAgg(column ='X0', aggfunc='mean'),\n","    avg_X1 = pd.NamedAgg(column ='X1', aggfunc='mean'))\n","test_DO_DT['maxprob_mean_dropout'] = test_DO_DT[['avg_X0', 'avg_X1']].max(axis=1)\n","#test_DO_DT['TRAP'] = np.where((test_DO_DT['avg_X1'] >= test_DO_DT['avg_X0']), 'Positive', 'Negative')\n","test_DO_DT = test_DO_DT.reset_index()  \n","\n","# ood classifier\n","y_pred = trap_ood.predict(test_DO_DT[['maxprob_mean_dropout']])\n","ood_dt = pd.DataFrame(y_pred); ood_dt.columns = ['Confidence']\n","ood_dt = pd.concat([test_DO_DT[[\"Peptide\", 'nlog2Rank',  'maxprob_mean_dropout']].reset_index(drop=True), \n","                    ood_dt.reset_index(drop=True)], axis=1) \n","  # output: peptide, nlog2, maxprob_mean_dropout, confidence \n","\n","# merge outputs \n","trap_pred['nlog2Rank']=trap_pred['nlog2Rank'].apply(lambda x:round(x,3))\n","ood_dt['nlog2Rank']=ood_dt['nlog2Rank'].apply(lambda x:round(x,3))\n","trap_output = pd.merge(trap_pred, ood_dt,  how='left', left_on=['Peptide','nlog2Rank'], right_on = ['Peptide','nlog2Rank'])\n","trap_output.rename(columns={'maxprob_mean_dropout': 'MCDropout'}, inplace=True)\n"],"metadata":{"id":"khCSggagNarM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#trap_output.rename(columns={\"MCDropout\": \"maxprob_mean_dropout\"})\n","trap_output.rename(columns={'maxprob_mean_dropout': 'MCDropout'}, inplace=True)\n","trap_output.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"TYf_TuNbDltx","executionInfo":{"status":"ok","timestamp":1674317788910,"user_tz":0,"elapsed":237,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"f2809406-46c5-4402-fa7d-522c38905073"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Peptide  nlog2Rank      TRAP  MCDropout  Confidence\n","0   AAIESFVSV      1.493  0.001471   5.757001    0.846314\n","1   ALAGGLYEY     -0.723  0.272071   1.210100    0.709710\n","2   ALFCHQYDI      0.199  0.030533   1.176501    0.708700\n","3  ALGALLILQL     -0.725  0.001783   5.379736    0.834980\n","4   ALKSDFKLV     -0.481  0.000014   8.076635    0.916004"],"text/html":["\n","  <div id=\"df-b282dfe8-96ec-4646-8a69-3f90cb888e92\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Peptide</th>\n","      <th>nlog2Rank</th>\n","      <th>TRAP</th>\n","      <th>MCDropout</th>\n","      <th>Confidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAIESFVSV</td>\n","      <td>1.493</td>\n","      <td>0.001471</td>\n","      <td>5.757001</td>\n","      <td>0.846314</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ALAGGLYEY</td>\n","      <td>-0.723</td>\n","      <td>0.272071</td>\n","      <td>1.210100</td>\n","      <td>0.709710</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ALFCHQYDI</td>\n","      <td>0.199</td>\n","      <td>0.030533</td>\n","      <td>1.176501</td>\n","      <td>0.708700</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ALGALLILQL</td>\n","      <td>-0.725</td>\n","      <td>0.001783</td>\n","      <td>5.379736</td>\n","      <td>0.834980</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ALKSDFKLV</td>\n","      <td>-0.481</td>\n","      <td>0.000014</td>\n","      <td>8.076635</td>\n","      <td>0.916004</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b282dfe8-96ec-4646-8a69-3f90cb888e92')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b282dfe8-96ec-4646-8a69-3f90cb888e92 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b282dfe8-96ec-4646-8a69-3f90cb888e92');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["import plotly.express as px\n","# plot \n","prediction = trap_output.drop_duplicates()\n","if trap_output.shape[0] > 40: prediction_dt = prediction.nlargest(40,'TRAP')\n","else: prediction_dt = prediction.nlargest(trap_output.shape[0],'TRAP')\n","fig_output = px.bar(prediction_dt, \n","              x=\"Peptide\", \n","              y=\"TRAP\", \n","              color=\"Confidence\", color_continuous_scale='sunsetdark',\n","              width=800, height=400, template=\"simple_white\").add_shape( # add a horizontal \"target\" line\n","          type=\"line\", line_color=\"salmon\", line_width=3, opacity=1, line_dash=\"dot\",\n","          x0=0, x1=1, xref=\"paper\", y0=0.5, y1=0.5, yref=\"y\")\n","fig_output.update_layout(transition_duration=500)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"MqUbVI_2NatL","executionInfo":{"status":"ok","timestamp":1674317131507,"user_tz":0,"elapsed":229,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"fa7852c5-4ad8-4fb0-83c9-94d5e5881a3e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"3f0f51da-6875-4e8c-9e9f-2ce9f206873f\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3f0f51da-6875-4e8c-9e9f-2ce9f206873f\")) {                    Plotly.newPlot(                        \"3f0f51da-6875-4e8c-9e9f-2ce9f206873f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Peptide=%{x}<br>TRAP=%{y}<br>Confidence=%{marker.color}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":[0.9377322447692786,0.9184283211346674,0.9279520856803053,0.8239220791485276,0.8185850939696026,0.8031985194983227,0.7434827637743361,0.6720859294662304,0.6762466972094937,0.7448732875499502,0.6980612884290435,0.7411331807155415,0.7691678029042801,0.7388872041423562,0.7326188858357903,0.6980612884290435,0.6903908327486175,0.6973080883611182,0.7106487204163775,0.6778176431519899,0.6970646940776979,0.6752692725800106,0.6889229018841118,0.6985251812313988,0.669095580109711,0.6782713962692041,0.7857679953130584,0.7461284325003116,0.6979084429530938,0.714506382587133,0.7434207912403764,0.7190647023146016,0.7114357545718917,0.7171351818269339,0.709709825528531,0.7607428678359598,0.6920015444325442,0.7758385153718795,0.7795221730462852,0.6994718167480556],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"LMAPLSPGA\",\"YITAAYVEV\",\"GLSSVALAFL\",\"ALSTVRVGA\",\"RLLLHSSNL\",\"LLLERGYDV\",\"KLSDVEMAT\",\"FVMRNHDVVL\",\"TLTSWSLAA\",\"EMDDFEIVV\",\"SLHLDAWTI\",\"ILFSAAKHSV\",\"ILPDFLPII\",\"VLSSVNSNLL\",\"MLQQFTVKL\",\"SLHLDAWTI\",\"VLAADIQQC\",\"GNLPDIEVRL\",\"YIRFFITYV\",\"YLRLQPDRV\",\"REMIPAVLPL\",\"LLMRYLKAI\",\"RLDLLMRYL\",\"LLAMAFDHYV\",\"IMEEVWYFL\",\"NLAEAQSAA\",\"WLSEDEIML\",\"FLLICGLQQV\",\"AVVGPLPTM\",\"FLEEIILKSL\",\"GLAVNLSQI\",\"MLDSRSTNRV\",\"LLLGDMDQGI\",\"NIYPNIIAM\",\"ALAGGLYEY\",\"GTIGLFLPL\",\"LEMDDFEIVV\",\"ALQQLTTHM\",\"VMFIGVNLT\",\"AMGNELIQVL\"],\"xaxis\":\"x\",\"y\":[0.9999535083770752,0.9998929500579834,0.9998595714569092,0.9998542070388794,0.9975796341896057,0.9972710013389587,0.9924345016479492,0.9922940731048584,0.9908340573310852,0.9895474910736084,0.9641516208648682,0.961649477481842,0.9554356932640076,0.8982535004615784,0.8923702836036682,0.8705866932868958,0.8645646572113037,0.8379616737365723,0.826073944568634,0.786460816860199,0.7597014307975769,0.687795102596283,0.62738436460495,0.5885361433029175,0.5680066347122192,0.5254526734352112,0.4996958374977112,0.4960007071495056,0.47734636068344116,0.3480445146560669,0.3009292483329773,0.2896949350833893,0.2894774377346039,0.28914874792099,0.27207085490226746,0.2373601794242859,0.21644330024719238,0.1776570975780487,0.10041506588459015,0.10005311667919159],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Peptide\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"TRAP\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Confidence\"}},\"colorscale\":[[0.0,\"rgb(252, 222, 156)\"],[0.16666666666666666,\"rgb(250, 164, 118)\"],[0.3333333333333333,\"rgb(240, 116, 110)\"],[0.5,\"rgb(227, 79, 111)\"],[0.6666666666666666,\"rgb(220, 57, 119)\"],[0.8333333333333334,\"rgb(185, 37, 122)\"],[1.0,\"rgb(124, 29, 111)\"]]},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"height\":400,\"width\":800,\"shapes\":[{\"line\":{\"color\":\"salmon\",\"dash\":\"dot\",\"width\":3},\"opacity\":1,\"type\":\"line\",\"x0\":0,\"x1\":1,\"xref\":\"paper\",\"y0\":0.5,\"y1\":0.5,\"yref\":\"y\"}],\"transition\":{\"duration\":500}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('3f0f51da-6875-4e8c-9e9f-2ce9f206873f');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["trap_output.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3yADeJNpNazI","executionInfo":{"status":"ok","timestamp":1674317564302,"user_tz":0,"elapsed":278,"user":{"displayName":"Chloe H. Lee","userId":"03823430786621750797"}},"outputId":"942523d2-3a39-4d99-de23-077508538741"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Peptide  nlog2Rank      TRAP  maxprob_mean_dropout  Confidence\n","0   AAIESFVSV      1.493  0.001471              5.757001    0.846314\n","1   ALAGGLYEY     -0.723  0.272071              1.210100    0.709710\n","2   ALFCHQYDI      0.199  0.030533              1.176501    0.708700\n","3  ALGALLILQL     -0.725  0.001783              5.379736    0.834980\n","4   ALKSDFKLV     -0.481  0.000014              8.076635    0.916004"],"text/html":["\n","  <div id=\"df-6ebcb289-7ab5-44c6-b6f4-11082bb894ea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Peptide</th>\n","      <th>nlog2Rank</th>\n","      <th>TRAP</th>\n","      <th>maxprob_mean_dropout</th>\n","      <th>Confidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAIESFVSV</td>\n","      <td>1.493</td>\n","      <td>0.001471</td>\n","      <td>5.757001</td>\n","      <td>0.846314</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ALAGGLYEY</td>\n","      <td>-0.723</td>\n","      <td>0.272071</td>\n","      <td>1.210100</td>\n","      <td>0.709710</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ALFCHQYDI</td>\n","      <td>0.199</td>\n","      <td>0.030533</td>\n","      <td>1.176501</td>\n","      <td>0.708700</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ALGALLILQL</td>\n","      <td>-0.725</td>\n","      <td>0.001783</td>\n","      <td>5.379736</td>\n","      <td>0.834980</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ALKSDFKLV</td>\n","      <td>-0.481</td>\n","      <td>0.000014</td>\n","      <td>8.076635</td>\n","      <td>0.916004</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ebcb289-7ab5-44c6-b6f4-11082bb894ea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ebcb289-7ab5-44c6-b6f4-11082bb894ea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ebcb289-7ab5-44c6-b6f4-11082bb894ea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":44}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}